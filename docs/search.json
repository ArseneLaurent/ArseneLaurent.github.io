[
  {
    "objectID": "Stats_Final_Project_Code.html",
    "href": "Stats_Final_Project_Code.html",
    "title": "Stats Final Project Code",
    "section": "",
    "text": "library(tidyverse)\n \ndf &lt;- read_csv(\"Video_Games_Sales_as_at_22_Dec_2016.csv\")\n\nhead(df)\n\n# A tibble: 6 × 16\n  Name       Platform Year_of_Release Genre Publisher NA_Sales EU_Sales JP_Sales\n  &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Wii Sports Wii      2006            Spor… Nintendo      41.4    29.0      3.77\n2 Super Mar… NES      1985            Plat… Nintendo      29.1     3.58     6.81\n3 Mario Kar… Wii      2008            Raci… Nintendo      15.7    12.8      3.79\n4 Wii Sport… Wii      2009            Spor… Nintendo      15.6    10.9      3.28\n5 Pokemon R… GB       1996            Role… Nintendo      11.3     8.89    10.2 \n6 Tetris     GB       1989            Puzz… Nintendo      23.2     2.26     4.22\n# ℹ 8 more variables: Other_Sales &lt;dbl&gt;, Global_Sales &lt;dbl&gt;,\n#   Critic_Score &lt;dbl&gt;, Critic_Count &lt;dbl&gt;, User_Score &lt;chr&gt;, User_Count &lt;dbl&gt;,\n#   Developer &lt;chr&gt;, Rating &lt;chr&gt;\n\n\n\ndf_clean &lt;- df |&gt;\n  select(Name, Genre, User_Score) |&gt;\n  filter(!is.na(Genre), !is.na(User_Score), User_Score != \"tbd\", Genre != \"Misc\") |&gt;\n  mutate(User_Score = as.numeric(User_Score))\ntable(df_clean$Genre)\n\n\n      Action    Adventure     Fighting     Platform       Puzzle       Racing \n        1830          300          399          428          128          641 \nRole-Playing      Shooter   Simulation       Sports     Strategy \n         743          924          344         1103          311 \n\n\n\nanova_result &lt;- aov(User_Score ~ Genre, data = df_clean)\nsummary(anova_result)\n\n              Df Sum Sq Mean Sq F value Pr(&gt;F)    \nGenre         10    265  26.468   12.02 &lt;2e-16 ***\nResiduals   7140  15719   2.201                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntukey_result &lt;- TukeyHSD(anova_result)\nprint(tukey_result)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = User_Score ~ Genre, data = df_clean)\n\n$Genre\n                                diff          lwr          upr     p adj\nAdventure-Action         0.078956284 -0.218606446  0.376519014 0.9988855\nFighting-Action          0.248462550 -0.015485189  0.512410289 0.0866685\nPlatform-Action          0.247358153 -0.009143072  0.503859379 0.0702693\nPuzzle-Action            0.120956284 -0.315811622  0.557724191 0.9983922\nRacing-Action           -0.017850268 -0.237108909  0.201408373 1.0000000\nRole-Playing-Action      0.565471762  0.357657741  0.773285783 0.0000000\nShooter-Action          -0.012160599 -0.204955411  0.180634213 1.0000000\nSimulation-Action        0.080549307 -0.200187857  0.361286472 0.9978303\nSports-Action           -0.092846980 -0.274950204  0.089256245 0.8644124\nStrategy-Action          0.241133133 -0.051873532  0.534139798 0.2235348\nFighting-Adventure       0.169506266 -0.195555557  0.534568088 0.9218860\nPlatform-Adventure       0.168401869 -0.191312745  0.528116484 0.9178162\nPuzzle-Adventure         0.042000000 -0.462349015  0.546349015 1.0000000\nRacing-Adventure        -0.096806552 -0.430986260  0.237373155 0.9976485\nRole-Playing-Adventure   0.486515478  0.159730544  0.813300411 0.0000888\nShooter-Adventure       -0.091116883 -0.408562256  0.226328490 0.9978233\nSimulation-Adventure     0.001593023 -0.375786203  0.378972250 1.0000000\nSports-Adventure        -0.171803264 -0.482871278  0.139264750 0.7932526\nStrategy-Adventure       0.162176849 -0.224416776  0.548770474 0.9596879\nPlatform-Fighting       -0.001104397 -0.333549031  0.331340238 1.0000000\nPuzzle-Fighting         -0.127506266 -0.612782228  0.357769697 0.9989761\nRacing-Fighting         -0.266312818 -0.570945232  0.038319596 0.1524710\nRole-Playing-Fighting    0.317009212  0.020507571  0.613510854 0.0245254\nShooter-Fighting        -0.260623149 -0.546798611  0.025552314 0.1131310\nSimulation-Fighting     -0.167913242 -0.519395691  0.183569206 0.9070380\nSports-Fighting         -0.341309529 -0.620393998 -0.062225061 0.0039991\nStrategy-Fighting       -0.007329417 -0.368687220  0.354028386 1.0000000\nPuzzle-Platform         -0.126401869 -0.607668147  0.354864408 0.9989797\nRacing-Platform         -0.265208421 -0.563412005  0.032995162 0.1350622\nRole-Playing-Platform    0.318113609  0.028221054  0.608006163 0.0180018\nShooter-Platform        -0.259518752 -0.538840905  0.019803401 0.0965682\nSimulation-Platform     -0.166808846 -0.512734244  0.179116552 0.9016910\nSports-Platform         -0.340205133 -0.612257720 -0.068152546 0.0028001\nStrategy-Platform       -0.006225020 -0.362179977  0.349729937 1.0000000\nRacing-Puzzle           -0.138806552 -0.601298393  0.323685288 0.9968423\nRole-Playing-Puzzle      0.444515478 -0.012661751  0.901692707 0.0652391\nShooter-Puzzle          -0.133116883 -0.583665649  0.317431883 0.9972276\nSimulation-Puzzle       -0.040406977 -0.535015616  0.454201663 1.0000000\nSports-Puzzle           -0.213803264 -0.659881660  0.232275132 0.9051910\nStrategy-Puzzle          0.120176849 -0.381497604  0.621851302 0.9995446\nRole-Playing-Racing      0.583322030  0.325796951  0.840847109 0.0000000\nShooter-Racing           0.005689669 -0.239875675  0.251255013 1.0000000\nSimulation-Racing        0.098399576 -0.220890033  0.417689184 0.9960739\nSports-Racing           -0.074996712 -0.312260453  0.162267030 0.9951752\nStrategy-Racing          0.258983401 -0.071145974  0.589112776 0.2894163\nShooter-Role-Playing    -0.577632361 -0.813035534 -0.342229188 0.0000000\nSimulation-Role-Playing -0.484922455 -0.796464057 -0.173380852 0.0000297\nSports-Role-Playing     -0.658318742 -0.885048534 -0.431588949 0.0000000\nStrategy-Role-Playing   -0.324338629 -0.646980412 -0.001696846 0.0474768\nSimulation-Shooter       0.092709906 -0.209020672  0.394440484 0.9961690\nSports-Shooter          -0.080686381 -0.293734663  0.132361902 0.9804661\nStrategy-Shooter         0.253293732 -0.059884958  0.566472422 0.2465809\nSports-Simulation       -0.173396287 -0.468409993  0.121617419 0.7225472\nStrategy-Simulation      0.160583826 -0.213213456  0.534381108 0.9526699\nStrategy-Sports          0.333980113  0.027267483  0.640692742 0.0197723\n\n\n\nplot(anova_result)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(df_clean, aes(x = Genre, y = User_Score)) +\n  geom_boxplot(fill = \"skyblue\") +\n  theme_minimal() +\n  labs(title = \"User Scores by Video Game Genre\", x = \"Genre\", y = \"User Score\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "Project_4.html",
    "href": "Project_4.html",
    "title": "Ethics of AI in the Hiring Process",
    "section": "",
    "text": "The use of AI in the hiring process is becoming ever more prominent as advances in the technology are made. This can range from using AI to automatically filter out duplicate applications to using AI to evaluate whether a candidate is suitable for a job, whether that be by simply cross referencing the applicant’s resume and the job requirements, or fully using AI to select highly valued candidates after being trained to be able to distinguish between different values of candidates. Using AI in the hiring process comes with its own set of ethical dilemmas though. Amazon found that its hiring AI was discriminating against women, despite never being explicitly taught to do so.\nAmazon had originally wanted to teach their AI to return the top few most promising candidates when given a list of applications. However, they inadvertently trained the AI to prefer male applicants over females. The data used to train the AI was collected over the course of 10 years and consisted of applications that the company had received during that period of time. This means that, while consent was not explicitly given by the people who submitted those applications, the resumes were willingly handed over to Amazon, who then used them to train their AI program. From what the Reuters article describes, none of the applications were excluded from being used to train the AI.\nHowever, there is an issue with the data being used nonetheless. When using data, especially when used to train AI into recognizing certain patterns and then apply them, it is of utmost importance to ensure that the data being used accurately represents the group that the AI will be asked to evaluate. In Amazon’s case though, the majority of applicants were men due to how male-dominated the tech industry is. Dastin mentions this, saying that “… Amazon’s computer models were trained to vet applicants by observing patterns in resumes submitted to the company over a 10-year period. Most came from men, a reflection of male dominance across the tech industry.” This means that when the AI was learning the patterns it was supposed to be recognizing and applying, it developed a preference for male candidates.\nIn general, using AI to evaluate candidates for a position runs the risk of falling into dangerous biases in the same way that Amazon did. An article from the University of Southern California mentions how AI might be used to hire people based on their proximity to the company they applied to. While companies might use this information to hire locals or those who could have shorter commutes and therefore be more easily available should there be an issue, this runs the risk of becoming discriminatory against minorities. If the AI is trained on applications that come from people who live in rich white neighborhoods, it could quickly begin to disqualify applications that come from people who live in minority communities but that are just as, if not more, qualified for the position.\nIt’s also important for people to be aware of what their data is being used for when using people’s data for anything, including training AI programs. As mentioned previously, while applicants willingly handed over their data, they likely were not made aware of exactly what their data was going to be used for after they were taken into consideration for the position. Informed consent could have been possible by adding a required field to the application that asks if the applicant is willing to submit their data for use in AI training, though that might open up other hidden biases in the training of the program. It’s difficult to provide informed consent for unseen applications, but as long as the use of the data doesn’t stray too far from being used to train the AI, what the AI does with that training is well within the boundaries of informed consent.\nCitations:\n\nDastin, Jeffrey. “Amazon Scraps Secret AI Recruiting Tool That Showed Bias against Women.” Reuters, 11 Oct. 2018, www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G/.\nUniversity of Southern California. “Artificial Intelligence in HR: How AI Is Changing Hiring | USC Online Communication Degree.” Communicationmgmt.usc.edu, 15 Nov. 2023, communicationmgmt.usc.edu/blog/ai-in-hr-how-artificial-intelligence-is-changing-hiring."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Arsene Laurent",
    "section": "",
    "text": "Arsene is a student at Pomona College majoring in Computer Science and Geology with a minor in Data Science. In his free time, he plays video games, does origami, and competes as part of the Claremont Men’s Volleyball Club. He is involved in the Pomona LXA and Claremont Colleges ALPFA chapter, and is a Posse Scholar from Miami, FL.\n \n  \n   \n  \n     LinkedIn\n  \n  \n     Github\n  \n  \n     Code for this Website"
  },
  {
    "objectID": "ds002_project2.html",
    "href": "ds002_project2.html",
    "title": "Netflix Analysis",
    "section": "",
    "text": "Code\nnetflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2021/2021-04-20/netflix_titles.csv')\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(ggthemes)\n\n\n\n\nCode\nplot_data&lt;- netflix_titles |&gt;\n  filter(str_detect(listed_in, \"(?&lt;=Action & ).*Adventure\"), !is.na(country)) |&gt;\n  group_by(country) |&gt;\n  summarize(action_count = n(),.groups = \"drop\") |&gt;\n  arrange(desc(action_count)) |&gt;\n  head(10)\n\n\n\n\nCode\nggplot(plot_data, aes(x = reorder(country, action_count), y = action_count)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Top 10 Countries with the Most Action Movies\", x = \"Country\", y = \"Number of Action Movies\") +\n  theme_solarized(light = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_fill_grey()\n\n\n\n\n\n\n\n\n\nThis shows us that the largest producer of the action movies on Netflix was the United States by far, with India coming in second, and China and Hong Kong taking up a total 3 of the top 10 spots.\n\n\nCode\nplot_data2 &lt;- netflix_titles |&gt;\n  mutate(year_added = str_extract(date_added, \"\\\\d{4}\"))\n\nggplot(plot_data2, aes(x = year_added)) +\n  geom_bar() +\n  facet_wrap(~type) +\n  theme_solarized(light = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nWith this data, we can see that in all years, Netflix added more movies to its repertoire than it did TV shows.\n\n\nCode\nplot_data3 &lt;- netflix_titles |&gt;\n  mutate(listed_in = str_split(listed_in, \", *\")) |&gt;\n  unnest(listed_in) |&gt;\n  group_by(listed_in) |&gt;\n  summarize(genre_count = n(), .groups = \"drop\") |&gt;\n  arrange(desc(genre_count)) |&gt;\n  head(10)\n\nggplot(plot_data3, aes(x = reorder(listed_in, genre_count), y = genre_count)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Top 10 Most Common Genres on Netflix\",\n    x = \"Genre\",\n    y = \"Count\"\n  ) +\n  theme_solarized(light = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe most common genre on Netflix is International Movies, with Dramas and Comedies close behind. This is likely a bit skewed since any movie not produced in the US is an international movie. Hence, the most popular genre excluding International Movies is Dramas\nHere is a link to the original data by Shivam Bansal: https://www.kaggle.com/datasets/shivamb/netflix-shows"
  },
  {
    "objectID": "Blackjack_Simulation_Presentation.html#goals",
    "href": "Blackjack_Simulation_Presentation.html#goals",
    "title": "Blackjack Simulation Presentation",
    "section": "Goals",
    "text": "Goals\nFor this project, I wanted to create a simulation to model the probability of winning versus the dealer in blackjack, assuming that both the player and the dealer employ standard blackjack strategy of hitting until you get 17 or higher. For the purposes of this simulation, we ignore the option to split."
  },
  {
    "objectID": "Blackjack_Simulation_Presentation.html#implementation",
    "href": "Blackjack_Simulation_Presentation.html#implementation",
    "title": "Blackjack Simulation Presentation",
    "section": "Implementation",
    "text": "Implementation\n\nCreate a function that:\n\nAdds the appropriate number of each card into a “deck”\nShuffles the “deck” for use in our simulation\nAssigns the first two cards in the deck to the player, and the next two to the dealer, removing all four from the deck\nKeeps drawing cards for both player and dealer until the sum of of each hand is greater than or equal to 17\nCompares the sum of each hand and returns the result for the player\n\nCreate another function that:\n\nReturns the sum of the selected hand\nRassigns the value of an Ace as either 1 or 11 depending on the best choice"
  },
  {
    "objectID": "Blackjack_Simulation_Presentation.html#code",
    "href": "Blackjack_Simulation_Presentation.html#code",
    "title": "Blackjack Simulation Presentation",
    "section": "Code",
    "text": "Code\n\n\nCode\nlibrary(purrr)\nlibrary(ggthemes)\n\nsimulate_blackjack_game &lt;- function() {\n\n  deck &lt;- c(rep(2:10, 4), rep(10, 12), rep(11, 4)) \n  deck &lt;- sample(deck, length(deck), replace = FALSE)\n  \n\n  player_hand &lt;- deck[1:2]\n  dealer_hand &lt;- deck[3:4]\n  deck &lt;- deck[-(1:4)] \n  hand_total &lt;- function(hand) {\n    total &lt;- sum(hand)\n    num_aces &lt;- sum(hand == 11)\n  \n    while (total &gt; 21 & num_aces &gt; 0) {\n      total &lt;- total - 10\n      num_aces &lt;- num_aces - 1\n    }\n    \n    return(total)\n  }\n  \n \n  while (hand_total(player_hand) &lt; 17) {\n    player_hand &lt;- c(player_hand, deck[1])  \n    deck &lt;- deck[-1] \n  }\n  player_total &lt;- hand_total(player_hand)\n  \n\n  while (hand_total(dealer_hand) &lt; 17) {\n    dealer_hand &lt;- c(dealer_hand, deck[1]) \n    deck &lt;- deck[-1] \n  }\n  dealer_total &lt;- hand_total(dealer_hand)\n\n  if (player_total &gt; 21) {\n    return(\"Loss\") \n  } else if (dealer_total &gt; 21 | player_total &gt; dealer_total) {\n    return(\"Win\") \n  } else if (player_total == dealer_total) {\n    return(\"Push\") \n  } else {\n    return(\"Loss\") \n  }\n}\n\nnum_simulations &lt;- 100000\nresults &lt;- map_chr(1:num_simulations, ~ simulate_blackjack_game())\n\n\nwin_prob &lt;- mean(results == \"Win\")\nloss_prob &lt;- mean(results == \"Loss\")\npush_prob &lt;- mean(results == \"Push\")\n\n\n\n\nCode\ncat(\"Estimated probability of winning:\", win_prob, \"\\n\")\n\n\nEstimated probability of winning: 0.41182 \n\n\nCode\ncat(\"Estimated probability of losing:\", loss_prob, \"\\n\")\n\n\nEstimated probability of losing: 0.48583 \n\n\nCode\ncat(\"Estimated probability of a push (tie):\", push_prob, \"\\n\")\n\n\nEstimated probability of a push (tie): 0.10235"
  },
  {
    "objectID": "Blackjack_Simulation_Presentation.html#graph",
    "href": "Blackjack_Simulation_Presentation.html#graph",
    "title": "Blackjack Simulation Presentation",
    "section": "Graph",
    "text": "Graph\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(purrr)\ndf &lt;- data.frame(Result = c(\"Win\", \"Loss\", \"Push\"), Probability = c(win_prob, loss_prob, push_prob))\n\nggplot(df, aes(x = Result, y = Probability, fill = Result)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Estimated Probabilities in Single-Deck Blackjack\", y = \"Probability\", x = \"Game Outcome\") +\n  theme_minimal() + theme_solarized(light = FALSE)"
  },
  {
    "objectID": "Blackjack_Simulation_Presentation.html#analysis",
    "href": "Blackjack_Simulation_Presentation.html#analysis",
    "title": "Blackjack Simulation Presentation",
    "section": "Analysis",
    "text": "Analysis\n\nThe graph and the numbers both show that the probability of losing is around 8% greater than the probability of winning using this strategy\nEven though the strategy allows for winning around 40% of the time, you would still lose more often than you win\nIt might be best to employ a more sophisticated strategy\n\nBasing the decision on whether to hit or stand on the cards that the dealer is showing, lessening the chances that the player busts if it’s likely that the dealer will bust if the player stands instead of hitting, even if the player has a hand less than 17"
  },
  {
    "objectID": "ChocolateRatings.html",
    "href": "ChocolateRatings.html",
    "title": "Chocolate Ratings Analysis",
    "section": "",
    "text": "This data comes from the 2022-01-18 folder of the TidyTuesday GitHub repository. After selecting the relevant variables and creating a graph with average rating as our y-axis and Country on the x-axis, we can see that companies based in Chile had the highest average rating for their chocolate bars. Unfortunately, this data is highly skewed by the fact that there were only two Chilean companies who had their chocolate bars rated. Below is a graph plotting all of the data, showing which country’s companies had the highest rated chocolate bars.\n\n\n\n\n\n\n\n\n\nUnfortunately, this plot doesn’t offer us much more information on which country produces the “best” chocolate, though we can observe that the highest rated chocolate is pretty consistently within the 60-80\\(%\\) range of cocoa concentration.\nHere is a link to the original data by Brady Brelinski: https://flavorsofcacao.com/chocolate_database.html"
  },
  {
    "objectID": "ds002_project3.html",
    "href": "ds002_project3.html",
    "title": "Blackjack Simulation",
    "section": "",
    "text": "In this project, I originally wanted to calculate the probability of getting a royal flush in texas hold ’em poker. I then pivoted to the probability of being dealt a blackjack in blackjack. This was an idea that was more appealing to me, but I then realized that that probability was much too trivial. I then pivoted again to calculating the probability of winning versus the dealer in blackjack, using standard playing strategy where both the dealer and the player don’t hit past 17.\n\n\nCode\nlibrary(purrr)\nlibrary(ggthemes)\n\nsimulate_blackjack_game &lt;- function() {\n\n  deck &lt;- c(rep(2:10, 4), rep(10, 12), rep(11, 4)) \n  deck &lt;- sample(deck, length(deck), replace = FALSE)\n  \n\n  player_hand &lt;- deck[1:2]\n  dealer_hand &lt;- deck[3:4]\n  deck &lt;- deck[-(1:4)] \n  hand_total &lt;- function(hand) {\n    total &lt;- sum(hand)\n    num_aces &lt;- sum(hand == 11)\n  \n    while (total &gt; 21 & num_aces &gt; 0) {\n      total &lt;- total - 10\n      num_aces &lt;- num_aces - 1\n    }\n    \n    return(total)\n  }\n  \n \n  while (hand_total(player_hand) &lt; 17) {\n    player_hand &lt;- c(player_hand, deck[1])  \n    deck &lt;- deck[-1] \n  }\n  player_total &lt;- hand_total(player_hand)\n  \n\n  while (hand_total(dealer_hand) &lt; 17) {\n    dealer_hand &lt;- c(dealer_hand, deck[1]) \n    deck &lt;- deck[-1] \n  }\n  dealer_total &lt;- hand_total(dealer_hand)\n\n  if (player_total &gt; 21) {\n    return(\"Loss\") \n  } else if (dealer_total &gt; 21 | player_total &gt; dealer_total) {\n    return(\"Win\") \n  } else if (player_total == dealer_total) {\n    return(\"Push\") \n  } else {\n    return(\"Loss\") \n  }\n}\n\n\nnum_simulations &lt;- 100000\nresults &lt;- map_chr(1:num_simulations, ~ simulate_blackjack_game())\n\n\nwin_prob &lt;- mean(results == \"Win\")\nloss_prob &lt;- mean(results == \"Loss\")\npush_prob &lt;- mean(results == \"Push\")\n\n\ncat(\"Estimated probability of winning:\", win_prob, \"\\n\")\n\n\nEstimated probability of winning: 0.40572 \n\n\nCode\ncat(\"Estimated probability of losing:\", loss_prob, \"\\n\")\n\n\nEstimated probability of losing: 0.49184 \n\n\nCode\ncat(\"Estimated probability of a push (tie):\", push_prob, \"\\n\")\n\n\nEstimated probability of a push (tie): 0.10244 \n\n\nCode\nlibrary(ggplot2)\ndf &lt;- data.frame(Result = c(\"Win\", \"Loss\", \"Push\"), Probability = c(win_prob, loss_prob, push_prob))\n\nggplot(df, aes(x = Result, y = Probability, fill = Result)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Estimated Probabilities in Single-Deck Blackjack\", y = \"Probability\", x = \"Game Outcome\") +\n  theme_minimal() + theme_solarized(light = FALSE)\n\n\n\n\n\n\n\n\n\nThe graph here shows us that, using a standard strategy, the player has around an 8% greater chance of losing than winning. This tells us that, though the standard strategy is decent, allowing for a win around 40% of the time, it would be prudent for the player to look to employ a more advanced strategy. This would involve basing the decision on whether to hit or stand on the cards that the dealer has been dealt, rather than solely basing that decision on the sum of the player’s own cards. Even more advanced strategy cold involve counting cards, but in a casino scenario or even amongst friends such a strategy could get the player into serious trouble."
  },
  {
    "objectID": "LondonMarathon.html",
    "href": "LondonMarathon.html",
    "title": "London Marathon Analysis",
    "section": "",
    "text": "This data comes from the 2023-04-25 folder of the TidyTuesday GitHub repository. After selecting the relevant variables and plotting, distinguishing athlete nationality by color and separating into 4 different graphs based on category. From these plots, we can notice that while winning times have decreased slightly for the Men and Women categories over the past 4 decades, times for the Wheelchair Women and Wheelchair Men categories have dramatically improved in the same amount of time.\nWe can also see that men generally have shorter times than women in either category, and that the winners for the past decade or so have consistently been from the same countries in each category, meaning that each category has a couple of countries that consistently dominate.\nHere is a link to the original data repository by nrennie on GitHub: https://github.com/nrennie/LondonMarathon, scraped from Wikipedia (1 November 2022) on London Marathon winners, and general data."
  },
  {
    "objectID": "Project_5.html",
    "href": "Project_5.html",
    "title": "Traffic Stops by Race in FL, OR, and WA",
    "section": "",
    "text": "Code\ncon_traffic &lt;- DBI::dbConnect(\n\n  RMariaDB::MariaDB(),\n\n  dbname = \"traffic\",\n\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n\n)\n\n\nIn this project, I plan to use the data from the Florida Statewide, Oregon Statewide, and Washington Statewide tables from the Stanford Open Policing Project dataset to compare the percentages of the stops that each race documented in the table was a part of. I plan to do this by first counting all of the stops in each table, then counting the number of stops each different race had in each state. I will then find the percentage of stops each race was involved in, and store those numbers in a new dataframe. Using this dataframe, I will visualize the data in a bar graph to help demonstrate the races that were involved in the most traffic stops in each of our states of interest.\n\n\nCode\nlibrary(DBI)\nget_stops_by_race &lt;- dbGetQuery(con_traffic, \"\nSELECT \n  'Florida' AS state,\n  subject_race,\n  COUNT(*) AS stop_count,\n  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM fl_statewide_2020_04_01), 2) AS percent_of_total\nFROM fl_statewide_2020_04_01\nWHERE subject_race IS NOT NULL\nGROUP BY subject_race\n\nUNION ALL\n\n-- Oregon\nSELECT \n  'Oregon' AS state,\n  subject_race,\n  COUNT(*) AS stop_count,\n  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM or_statewide_2020_04_01), 2) AS percent_of_total\nFROM or_statewide_2020_04_01\nWHERE subject_race IS NOT NULL\nGROUP BY subject_race\n\nUNION ALL\n\n-- Washington\nSELECT \n  'Washington' AS state,\n  subject_race,\n  COUNT(*) AS stop_count,\n  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM wa_statewide_2020_04_01), 2) AS percent_of_total\nFROM wa_statewide_2020_04_01\nWHERE subject_race IS NOT NULL\nGROUP BY subject_race;\")\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggthemes)\n\nget_stops_by_race |&gt;\n  mutate(\n    state = factor(state, levels = c(\"Florida\", \"Oregon\", \"Washington\")),\n    subject_race = factor(subject_race)\n  ) |&gt;\n  ggplot(aes(x = subject_race, y = percent_of_total, fill = subject_race)) +\n  geom_col() +\n  facet_wrap(~ state) +\n  labs(\n    title = \"Traffic Stops by Race Across States\",\n    x = \"Race\",\n    y = \"Percentage of Stops\",\n    fill = \"Race\"\n  ) +\n  theme_solarized(light = FALSE, base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nHere, we can clearly see that White people were the predominant race involved in traffic stops in all three of our states of interest. However, we notice that Florida had a much higher Hispanic and Black percentage than every other state. It’s also worth noting that Washington and Oregon both had relatively high Hispanic percentages in their traffic stops with few other races coming too close, while Florida’s Black and Hispanic percentages were pretty similar.\n\n\nCode\ndbDisconnect(conn=con_traffic)"
  }
]