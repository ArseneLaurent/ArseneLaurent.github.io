[
  {
    "objectID": "Project_5.html",
    "href": "Project_5.html",
    "title": "Project 5",
    "section": "",
    "text": "Code\ncon_traffic &lt;- DBI::dbConnect(\n\n  RMariaDB::MariaDB(),\n\n  dbname = \"traffic\",\n\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n\n)\n\n\nIn this project, I plan to use the data from the Florida Statewide, Oregon Statewide, and Washington Statewide tables from the Stanford Open Policing Project dataset to compare the percentages of the stops that each race documented in the table was a part of. I plan to do this by first counting all of the stops in each table, then counting the number of stops each different race had in each state. I will then find the percentage of stops each race was involved in, and store those numbers in a new dataframe. Using this dataframe, I will visualize the data in a bar graph to help demonstrate the races that were involved in the most traffic stops in each of our states of interest.\n\n\nCode\nlibrary(DBI)\n\n\nWarning: package 'DBI' was built under R version 4.4.3\n\n\nCode\nget_stops_by_race &lt;- dbGetQuery(con_traffic, \"\nSELECT \n  'Florida' AS state,\n  subject_race,\n  COUNT(*) AS stop_count,\n  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM fl_statewide_2020_04_01), 2) AS percent_of_total\nFROM fl_statewide_2020_04_01\nWHERE subject_race IS NOT NULL\nGROUP BY subject_race\n\nUNION ALL\n\n-- Oregon\nSELECT \n  'Oregon' AS state,\n  subject_race,\n  COUNT(*) AS stop_count,\n  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM or_statewide_2020_04_01), 2) AS percent_of_total\nFROM or_statewide_2020_04_01\nWHERE subject_race IS NOT NULL\nGROUP BY subject_race\n\nUNION ALL\n\n-- Washington\nSELECT \n  'Washington' AS state,\n  subject_race,\n  COUNT(*) AS stop_count,\n  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM wa_statewide_2020_04_01), 2) AS percent_of_total\nFROM wa_statewide_2020_04_01\nWHERE subject_race IS NOT NULL\nGROUP BY subject_race;\")\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nget_stops_by_race |&gt;\n  mutate(\n    state = factor(state, levels = c(\"Florida\", \"Oregon\", \"Washington\")),\n    subject_race = factor(subject_race)\n  ) |&gt;\n  ggplot(aes(x = subject_race, y = percent_of_total, fill = subject_race)) +\n  geom_col() +\n  facet_wrap(~ state) +\n  labs(\n    title = \"Traffic Stops by Race Across States\",\n    x = \"Race\",\n    y = \"Percentage of Stops\",\n    fill = \"Race\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nHere, we can clearly see that White people were the predominant race involved in traffic stops in all three of our states of interest. However, we notice that Florida had a much higher Hispanic and Black percentage than every other state. It’s also worth noting that Washington and Oregon both had relatively high Hispanic percentages in their traffic stops with few other races coming too close, while Florida’s Black and Hispanic percentages were pretty similar.\n\n\nCode\ndbDisconnect(conn=con_traffic)"
  },
  {
    "objectID": "LondonMarathon.html",
    "href": "LondonMarathon.html",
    "title": "London Marathon Analysis",
    "section": "",
    "text": "This data comes from the 2023-04-25 folder of the TidyTuesday GitHub repository. After selecting the relevant variables and plotting, distinguishing athlete nationality by color and separating into 4 different graphs based on category. From these plots, we can notice that while winning times have decreased slightly for the Men and Women categories over the past 4 decades, times for the Wheelchair Women and Wheelchair Men categories have dramatically improved in the same amount of time.\nWe can also see that men generally have shorter times than women in either category, and that the winners for the past decade or so have consistently been from the same countries in each category, meaning that each category has a couple of countries that consistently dominate.\nHere is a link to the original data repository by nrennie on GitHub: https://github.com/nrennie/LondonMarathon"
  },
  {
    "objectID": "ds002_project3.html",
    "href": "ds002_project3.html",
    "title": "Project 3",
    "section": "",
    "text": "In this project, I originally wanted to calculate the probability of getting a royal flush in texas hold em poker. I then pivoted to the probability of being dealt a blackjack in blackjack. This was an idea that was more appealing to me, but I then realized that that probability was much too trivial. I then pivoted again to calculating the probability of winning versus the dealer in blackjack, using standard playing strategy where both the dealer and the player don’t hit past 17.\n\n\nCode\nlibrary(purrr)\nlibrary(ggthemes)\n\nsimulate_blackjack_game &lt;- function() {\n\n  deck &lt;- c(rep(2:10, 4), rep(10, 12), rep(11, 4)) \n  deck &lt;- sample(deck, length(deck), replace = FALSE)\n  \n\n  player_hand &lt;- deck[1:2]\n  dealer_hand &lt;- deck[3:4]\n  deck &lt;- deck[-(1:4)] \n  hand_total &lt;- function(hand) {\n    total &lt;- sum(hand)\n    num_aces &lt;- sum(hand == 11)\n  \n    while (total &gt; 21 & num_aces &gt; 0) {\n      total &lt;- total - 10\n      num_aces &lt;- num_aces - 1\n    }\n    \n    return(total)\n  }\n  \n \n  while (hand_total(player_hand) &lt; 17) {\n    player_hand &lt;- c(player_hand, deck[1])  \n    deck &lt;- deck[-1] \n  }\n  player_total &lt;- hand_total(player_hand)\n  \n\n  while (hand_total(dealer_hand) &lt; 17) {\n    dealer_hand &lt;- c(dealer_hand, deck[1]) \n    deck &lt;- deck[-1] \n  }\n  dealer_total &lt;- hand_total(dealer_hand)\n\n  if (player_total &gt; 21) {\n    return(\"Loss\") \n  } else if (dealer_total &gt; 21 | player_total &gt; dealer_total) {\n    return(\"Win\") \n  } else if (player_total == dealer_total) {\n    return(\"Push\") \n  } else {\n    return(\"Loss\") \n  }\n}\n\n\nnum_simulations &lt;- 100000\nresults &lt;- map_chr(1:num_simulations, ~ simulate_blackjack_game())\n\n\nwin_prob &lt;- mean(results == \"Win\")\nloss_prob &lt;- mean(results == \"Loss\")\npush_prob &lt;- mean(results == \"Push\")\n\n\ncat(\"Estimated probability of winning:\", win_prob, \"\\n\")\n\n\nEstimated probability of winning: 0.40844 \n\n\nCode\ncat(\"Estimated probability of losing:\", loss_prob, \"\\n\")\n\n\nEstimated probability of losing: 0.49008 \n\n\nCode\ncat(\"Estimated probability of a push (tie):\", push_prob, \"\\n\")\n\n\nEstimated probability of a push (tie): 0.10148 \n\n\nCode\nlibrary(ggplot2)\ndf &lt;- data.frame(Result = c(\"Win\", \"Loss\", \"Push\"), Probability = c(win_prob, loss_prob, push_prob))\n\nggplot(df, aes(x = Result, y = Probability, fill = Result)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Estimated Probabilities in Single-Deck Blackjack\", y = \"Probability\", x = \"Game Outcome\") +\n  theme_minimal() + theme_solarized(light = FALSE)\n\n\n\n\n\n\n\n\n\nThe graph here shows us that, using a standard strategy, the player has around an 8% greater chance of losing than winning. This tells us that, though the standard strategy is decent, allowing for a win around 40% of the time, it would be prudent for the player to look to employ a more advanced strategy. This would involve basing the decision on whether to hit or stand on the cards that the dealer has been dealt, rather than solely basing that decision on the sum of the player’s own cards. Even more advanced strategy cold involve counting cards, but in a casino scenario or even amongst friends such a strategy could get the player into serious trouble."
  },
  {
    "objectID": "ChocolateRatings.html",
    "href": "ChocolateRatings.html",
    "title": "Chocolate Ratings Analysis",
    "section": "",
    "text": "This data comes from the 2022-01-18 folder of the TidyTuesday GitHub repository. After selecting the relevant variables and creating a graph with average rating as our y-axis and Country on the x-axis, we can see that companies based in Chile had the highest average rating for their chocolate bars. Unfortunately, this data is highly skewed by the fact that there were only two Chilean companies who had their chocolate bars rated. Below is a graph plotting all of the data, showing which country’s companies had the highest rated chocolate bars.\n\n\n\n\n\n\n\n\n\nUnfortunately, this plot doesn’t offer us much more information on which country produces the “best” chocolate, though we can observe that the highest rated chocolate is pretty consistently within the 60-80\\(%\\) range of cocoa concentration.\nHere is a link to the original data by Brady Brelinski: https://flavorsofcacao.com/chocolate_database.html"
  },
  {
    "objectID": "ds002_project2.html",
    "href": "ds002_project2.html",
    "title": "Mini-Project 2",
    "section": "",
    "text": "netflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2021/2021-04-20/netflix_titles.csv')\n\nRows: 7787 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): show_id, type, title, director, cast, country, date_added, rating,...\ndbl  (1): release_year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(ggthemes)\n\n\nplot_data&lt;- netflix_titles |&gt;\n  filter(str_detect(listed_in, \"(?&lt;=Action & ).*Adventure\"), !is.na(country)) |&gt;\n  group_by(country) |&gt;\n  summarize(action_count = n(),.groups = \"drop\") |&gt;\n  arrange(desc(action_count)) |&gt;\n  head(10)\n\n\nggplot(plot_data, aes(x = reorder(country, action_count), y = action_count, fill = action_count)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Top 10 Countries with the Most Action Movies\", x = \"Country\", y = \"Number of Action Movies\") +\n  theme_solarized(light = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThis shows us that the largest producer of the action movies on Netflix was the United States by far, with India coming in second, and China and Hong Kong taking up a total 3 of the top 10 spots.\n\nplot_data2 &lt;- netflix_titles |&gt;\n  mutate(year_added = str_extract(date_added, \"\\\\d{4}\"))\n\nggplot(plot_data2, aes(x = year_added)) +\n  geom_bar() +\n  facet_wrap(~type) +\n  theme_solarized(light = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nWith this data, we can see that in all years, Netflix added more movies to its repertoire than it did TV shows.\n\nplot_data3 &lt;- netflix_titles |&gt;\n  mutate(listed_in = str_split(listed_in, \", *\")) |&gt;\n  unnest(listed_in) |&gt;\n  group_by(listed_in) |&gt;\n  summarize(genre_count = n(), .groups = \"drop\") |&gt;\n  arrange(desc(genre_count)) |&gt;\n  head(10)\n\nggplot(plot_data3, aes(x = reorder(listed_in, genre_count), y = genre_count)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Top 10 Most Common Genres on Netflix\",\n    x = \"Genre\",\n    y = \"Count\"\n  ) +\n  theme_solarized(light = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe most common genre on Netflix is International Movies, with Dramas and Comedies close behind. This is likely a bit skewed since any movie not produced in the US is an international movie. Hence, the most popular genre excluding International Movies is Dramas\nHere is a link to the original data by Shivam Bansal: https://www.kaggle.com/datasets/shivamb/netflix-shows"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Arsene Laurent",
    "section": "",
    "text": "Arsene is a student at Pomona College hoping to attain a double major in Computer Science and Geology as well as a minor in Data Science. In his free time, he plays video games, does origami, and competes as part of the Claremont Men’s Volleyball Club.\n \n  \n   \n  \n     LinkedIn\n  \n  \n     Github\n  \n  \n     Code for this Website"
  },
  {
    "objectID": "Project_4.html",
    "href": "Project_4.html",
    "title": "Project 4",
    "section": "",
    "text": "The use of AI in the hiring process is becoming ever more prominent as advances in the technology are made. This can range from using AI to automatically filter out duplicate applications to using AI to evaluate whether a candidate is suitable for a job, whether that be by simply cross referencing the applicant’s resume and the job requirements, or fully using AI to select highly valued candidates after being trained to be able to distinguish between different values of candidates. Using AI in the hiring process comes with its own set of ethical dilemmas though. Amazon found that its hiring AI was discriminating against women, despite never being explicitly taught to do so.\nAmazon had originally wanted to teach their AI to return the top few most promising candidates when given a list of applications. However, they inadvertently trained the AI to prefer male applicants over females. The data used to train the AI was collected over the course of 10 years and consisted of applications that the company had received during that period of time. This means that, while consent was not explicitly given by the people who submitted those applications, the resumes were willingly handed over to Amazon, who then used them to train their AI program. From what the Reuters article describes, none of the applications were excluded from being used to train the AI.\nHowever, there is an issue with the data being used nonetheless. When using data, especially when used to train AI into recognizing certain patterns and then apply them, it is of utmost importance to ensure that the data being used accurately represents the group that the AI will be asked to evaluate. In Amazon’s case though, the majority of applicants were men due to how male-dominated the tech industry is. This means that when the AI was learning the patterns it was supposed to be recognizing and applying, it developed a preference for male candidates.\nIn general, using AI to evaluate candidates for a position runs the risk of falling into dangerous biases in the same way that Amazon did. An article from USCAnnenberg mentions how AI might be used to hire people based on their proximity to the company they applied to. This runs the risk of becoming discriminatory against minorities. If the AI is trained on applications that come from people who live in rich white neighborhoods, it could quickly begin to disqualify applications that come from people who live in minority communities but that are just as, if not more, qualified for the position.\nIt’s also important for people to be aware of what their data is being used for when using people’s data for anything, including training AI programs. As mentioned previously, while applicants willingly handed over their data, they likely were not made aware of exactly what their data was going to be used for after they were taken into consideration for the position. Informed consent could have been possible by adding a required field to the application that asks if the applicant is willing to submit their data for use in AI training, though that might open up other hidden biases in the training of the program. It’s difficult to provide informed consent for unseen applications, but as long as the use of the data doesn’t stray too far from being used to train the AI, what the AI does with that training is well within the boundaries of informed consent.\nCitations:\n\nDastin, J. (n.d.). Insight - Amazon scraps secret AI recruiting tool that showed bias against women | reuters. Reuters. https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G/\nHow artificial intelligence (AI) in HR is changing hiring. USC Online Communication Degree. (n.d.). https://communicationmgmt.usc.edu/blog/ai-in-hr-how-artificial-intelligence-is-changing-hiring"
  }
]