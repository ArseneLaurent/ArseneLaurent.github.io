---
title: "Ethics of AI in the Hiring Process"
format: html
---

The use of AI in the hiring process is becoming ever more prominent as advances in the technology are made. This can range from using AI to automatically filter out duplicate applications to using AI to evaluate whether a candidate is suitable for a job, whether that be by simply cross referencing the applicant's resume and the job requirements, or fully using AI to select highly valued candidates after being trained to be able to distinguish between different values of candidates. Using AI in the hiring process comes with its own set of ethical dilemmas though. Amazon found that its hiring AI was discriminating against women, despite never being explicitly taught to do so.

Amazon had originally wanted to teach their AI to return the top few most promising candidates when given a list of applications. However, they inadvertently trained the AI to prefer male applicants over females. The data used to train the AI was collected over the course of 10 years and consisted of applications that the company had received during that period of time. This means that, while consent was not explicitly given by the people who submitted those applications, the resumes were willingly handed over to Amazon, who then used them to train their AI program. From what the Reuters article describes, none of the applications were excluded from being used to train the AI.

However, there is an issue with the data being used nonetheless. When using data, especially when used to train AI into recognizing certain patterns and then apply them, it is of utmost importance to ensure that the data being used accurately represents the group that the AI will be asked to evaluate. In Amazon's case though, the majority of applicants were men due to how male-dominated the tech industry is. This means that when the AI was learning the patterns it was supposed to be recognizing and applying, it developed a preference for male candidates.

In general, using AI to evaluate candidates for a position runs the risk of falling into dangerous biases in the same way that Amazon did. An article from USCAnnenberg mentions how AI might be used to hire people based on their proximity to the company they applied to. This runs the risk of becoming discriminatory against minorities. If the AI is trained on applications that come from people who live in rich white neighborhoods, it could quickly begin to disqualify applications that come from people who live in minority communities but that are just as, if not more, qualified for the position.

It's also important for people to be aware of what their data is being used for when using people's data for anything, including training AI programs. As mentioned previously, while applicants willingly handed over their data, they likely were not made aware of exactly what their data was going to be used for after they were taken into consideration for the position. Informed consent could have been possible by adding a required field to the application that asks if the applicant is willing to submit their data for use in AI training, though that might open up other hidden biases in the training of the program. It's difficult to provide informed consent for unseen applications, but as long as the use of the data doesn't stray too far from being used to train the AI, what the AI does with that training is well within the boundaries of informed consent.

Citations:

- Dastin, J. (n.d.). Insight - Amazon scraps secret AI recruiting tool that showed bias against women | reuters. Reuters. https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G/ 

- How artificial intelligence (AI) in HR is changing hiring. USC Online Communication Degree. (n.d.). https://communicationmgmt.usc.edu/blog/ai-in-hr-how-artificial-intelligence-is-changing-hiring 
